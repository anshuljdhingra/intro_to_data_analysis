{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "by Carl Shan and Jen Selby at The Nueva School\n",
    "\n",
    "This notebook will demonstrate some code that uses `sklearn`'s `LogisticRegression` model to classify some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning about Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a common classification technique.\n",
    "\n",
    "Unlike linear regression, which predicts numerical outcomes, logistic regression outputs a number that is meant to represent the probability of a certain classification.\n",
    "\n",
    "Steps to learn about logistic regression:\n",
    "\n",
    "1. First, [watch this 15-minute video](https://www.youtube.com/embed/-Z2a_mzl9LM?feature=oembed&rel=0). It does a great job of breaking down in simple terms the intuition and math behind logistic regression.\n",
    "\n",
    "2. Then to read more about the model, check out [the content on the course notes](https://jennselby.github.io/MachineLearningCourseNotes/)\n",
    "\n",
    "3. Finally you can read more about Logisitic Regression in Python by following [this online guide.](https://www.linkedin.com/pulse/logistics-regression-using-ipython-jeffrey-strickland-ph-d-cmsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Read through the code below to make sure you understand it.\n",
    "2. Then, go to Canvas and pick a set of exercises (Standard or Advanced) to complete and submit.\n",
    "\n",
    "The rest of this notebook walks you through an example of using the logistic regression model.\n",
    "\n",
    "In this Jupyter Notebook, you will see the code behind how to build a logistic model to predict whether a plant is of Class A (tall and thin) or Class B (short and wide)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remember that you can run this cell with SHIFT+ENTER\n",
    "import numpy.random\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generating some fake data about plants we're going to use to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#  FAKE GENERATED DATA\n",
    "################################################################################\n",
    "\n",
    "# We have two types of plants\n",
    "\n",
    "# Let's have 100 PlantA and 100 PlantB data\n",
    "NUM_INPUTS = 100\n",
    "\n",
    "# Plant A tends to be taller (avg 60cm) and thinner (avg 8cm)\n",
    "PLANT_A_AVG_HEIGHT = 60.0\n",
    "PLANT_A_AVG_WIDTH = 8.0\n",
    "\n",
    "# Plant B tends to be shorter (avg 58cm) and wider (avg 10cm)\n",
    "PLANT_B_AVG_HEIGHT = 58.0\n",
    "PLANT_B_AVG_WIDTH = 10.0\n",
    "\n",
    "# Now we're going to generate some datapoints for PlantA and PlantB\n",
    "plantA_heights = numpy.random.normal(loc=PLANT_A_AVG_HEIGHT, size=NUM_INPUTS)\n",
    "plantA_widths = numpy.random.normal(loc=PLANT_A_AVG_WIDTH, size=NUM_INPUTS)\n",
    "\n",
    "plantB_heights = numpy.random.normal(loc=PLANT_B_AVG_HEIGHT, size=NUM_INPUTS)\n",
    "plantB_widths = numpy.random.normal(loc=PLANT_B_AVG_WIDTH, size=NUM_INPUTS)\n",
    "\n",
    "# We'll use 0 to represent Plant A and 1 for Plant B\n",
    "plantTypes = [0]*NUM_INPUTS + [1]*NUM_INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's put it in a pandas DataFrame\n",
    "data = {\n",
    "        'heights': np.concatenate([plantA_heights, plantB_heights]), \n",
    "        'widths': np.concatenate([plantA_widths, plantB_widths]), \n",
    "        'plantType': plantTypes\n",
    "       }\n",
    "\n",
    "plant_df = pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# PLOT\n",
    "################################################################################\n",
    "\n",
    "# put the generated points on the graph\n",
    "plt.scatter(plantA_heights, plantA_widths, c=\"red\", marker=\"o\")\n",
    "plt.scatter(plantB_heights, plantB_widths, c=\"blue\", marker=\"^\")\n",
    "\n",
    "plt.title(\"Height (cm) vs. Width (cm) for 2 Plant Types\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red dots are Plant A, and the blue dots are Plant B.\n",
    "\n",
    "There is a pretty obvious split between the two. So can we build a model that can accurately distinguish a new plant, given that we know its height and width, whether it's of Plant A or Plant B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Before going onto the next step, I highly encourage you to run the above cell (SHIFT+ENTER) and then make a few cells below to inspect what each of the variables (e.g., `plantA_heights`, `plant_inputs`) look like.\n",
    "\n",
    "The reason is that you generally want to know what your data looks like before you start modeling.\n",
    "\n",
    "For example, do you know how many rows of data there are? Are the data of type `int` or `float`? Are they in a single `list` or `lists` within a `list`? All of these can make a difference as you go on to build a logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fitting a model to our data\n",
    "\n",
    "Again, notice that by using the `sklearn` library, it takes very few lines of code to fit the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# MODEL TRAINING\n",
    "################################################################################\n",
    "plant_inputs = plant_df[['heights', 'widths']]\n",
    "types = data['plantType']\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(plant_inputs, types)\n",
    "\n",
    "# Let's see what the fitted parameters are\n",
    "print('Intercept: {0}  Parameters: {1}'.format(model.intercept_, model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Using our fitted model to make predictions on new data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, if it's good we can use it to make some predictions on new data.\n",
    "\n",
    "I'm going to create two new datapoints: one Plant A and one Plant B.\n",
    "\n",
    "I'm going to run these new plants through our model and see what it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# PREDICTION\n",
    "################################################################################\n",
    "\n",
    "newA_height = numpy.random.normal(loc=PLANT_A_AVG_HEIGHT)\n",
    "newA_width = numpy.random.normal(loc=PLANT_A_AVG_WIDTH)\n",
    "newB_height = numpy.random.normal(loc=PLANT_B_AVG_HEIGHT)\n",
    "newB_width = numpy.random.normal(loc=PLANT_B_AVG_WIDTH)\n",
    "\n",
    "inputs = [[newA_height, newA_width], [newB_height, newB_width]]\n",
    "\n",
    "print('Type predictions: {0}'.format(model.predict(inputs)))\n",
    "print('Probabilities: {0}'.format(model.predict_proba(inputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to read the above output (although you'll have slightly different numbers):\n",
    "\n",
    "```python\n",
    "Type predictions: [0 1]\n",
    "Probabilities: [\n",
    "                [0.9440462  0.0559538 ]\n",
    "                [0.16431453 0.83568547]\n",
    "               ]\n",
    "\n",
    "```\n",
    "\n",
    "The type predictions are the predictions for the first datapoint, followed by the second datapoint.\n",
    "\n",
    "So it predicted Plant A for the first datapoint, and Plant B second. Nicely done!\n",
    "\n",
    "But what does this mean?\n",
    "\n",
    "```python\n",
    "Probabilities: [\n",
    "                [0.9440462  0.0559538 ]\n",
    "                [0.16431453 0.83568547]\n",
    "               ]\n",
    "```\n",
    "\n",
    "Those contains the predicted probablities for both points.\n",
    "\n",
    "Notice that the first pair add up to 1, and so do the second pair.\n",
    "\n",
    "So `[0.9440462  0.0559538 ]` is basically the following `[prob_of_plantA, prob_of_plantB]` for the first datapoint we made and `[0.16431453 0.83568547]` is the same thing for the second datapoint we made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your assignment below\n",
    "\n",
    "Choose one of the set of exercises on the assignment and complete it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### YOUR CHOICE OF EXERCISES AND CODE / ANALYSIS BELOW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nteract": {
   "version": "0.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
